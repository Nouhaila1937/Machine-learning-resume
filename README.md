# Machine-learning-resume
soit la rÃ©gression linÃ©aire simple multiple polynomiale multivariÃ© ou univariÃ©  rÃ©gression logistique ou autre sont appelÃ©s des algorithme de machine learning 


## data split 
![image](https://github.com/user-attachments/assets/c09dbeb7-08a9-4e29-93a0-d20cfb3290dc)
dans cette image on a cette ligne 
```bash
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```
cette fonction doit respecter l'ordre parceque la fonction retourne ceci en ordre
```bash
rÃ©sultat = train_test_split(X, y, test_size=0.2)
X_train = rÃ©sultat[0]
X_test = rÃ©sultat[1]
y_train = rÃ©sultat[2]
y_test = rÃ©sultat[3]
```
du coup il faut respecter l'ordre de X_train....

## La normalisation 
La normalisation (ou standardisation) est trÃ¨s importante dans de nombreux cas, mais elle nâ€™est pas toujours obligatoire. Ã‡a dÃ©pend de lâ€™algorithme que tu utilises.

ğŸ” Si tu fais la normalisation sans vÃ©rifier lâ€™algo :
Voici ce qui peut arriver :
âœ… Cas 1 : Tu utilises un algo qui a besoin de normalisation
â¡ï¸ Par exemple : k-NN, SVM, rÃ©gression logistique, rÃ©gression linÃ©aire, etc.
ğŸ‘‰ Si tu normalises, câ€™est parfait ! Tu aides lâ€™algorithme Ã  mieux apprendre (convergence plus rapide, meilleure prÃ©cision, etc.)
âœ… Cas 2 : Tu utilises un algo qui nâ€™en a pas besoin
â¡ï¸ Par exemple : arbre de dÃ©cision, random forest, XGBoost, etc.
ğŸ‘‰ Si tu normalises :
Ce nâ€™est pas grave,
Mais Ã§a ne sert Ã  rien (Ã§a ne change ni les performances ni la logique),
Parfois, Ã§a peut ajouter de la complexitÃ© inutile ou ralentir un peu lâ€™entraÃ®nement.
Donc pas dangereux, mais pas utile non plus.
âš ï¸ Cas Ã  Ã©viter :
Si tu fais la normalisation aprÃ¨s avoir divisÃ© les donnÃ©es, attention Ã  ne pas normaliser sur tout le jeu de donnÃ©es, sinon :
âŒ Tu vas fuir l'information du test dans l'entraÃ®nement
(Ton modÃ¨le "verra" des infos du futur, ce qui est interdit dans le ML)









## Accuraccy
ici l'accuracy soit de calculer le RÂ² il est dans la rÃ©grÃ©ssion linÃ©aire 
soit il s'appelle l'accuraccy dans la classification
## RÃ©gression linÃ©aire simple:



## RÃ©gression linÃ©aire multiple:
```
f(x)=ax1+bx2+c
```
